---
layout: page
---

## CV (ru)

Олег Стрижеченко, 25 лет, Разработчик, специализируюсь на backend, linux, c, python, сетях.

Местонахождение: Россия, Екатеринбург. Буду рад релокации.

Зарплатные ожидания: 85000-200000 рублей/месяц (в России). Всё обсуждаемо и зависит от того:

- насколько прозрачны условия прироста ЗП
- где (страна, город)
- над чем (интересно, полезно для портфолио, греет душу, применимы имеющиеся навыки)
- и сколько (легко/сложно)

работать.

## Почему стоит взять меня работать

- способен адаптироваться к культуре разработки в компании, особенно если она логична и хороша.
- после некоторого времени, потраченного на знакомство с проектом и компанией, могу стать неплохим ментором для новчиков.
- знаком непонаслышке с такими ценностями разработки ПО как надёжность, поддерживаемость и производительность.
- люблю тестирование, умею приоретизировать то, что нужно протестировать в первую очередь.
- способен неплохо абстрагироваться от своей сущности разработчика, когда необходимо представить себя на месте пользователя продукта.
- непрерывно обучаюсь (английский язык, книги, coursera, codewars, hackerrank) и как минимум ближайшие лет пять планирую не прекращать это.
- имею богатый опыт работы (тестирование, инфраструктура, разработка, общение с клиентами, документация, управление проектом и даже немного маркетинга).
- подхожу с разных сторон к решению проблем, когда с технической стороной проблема - обычно она быстро решается организационными методами.
- прекрасно себя чувствую, когда от бизнеса есть точные рекомендации по уровням качества, надёжности и скорости разработки.
- не курю, а следовательно могу находиться в состоянии потока значительно дольше.
- большой объём времени, потраченного на относительно низкоуровневое и сетевое программирование позволяет быстро разбираться во многих проблемах, которые сперва кажутся "чёрным ящиком".
- умею искать готовые opensource решения и адаптировать их, при необходимости.

## В какие стороны хочу развиваться

- облака, хостинги, виртуализация, мониторинги, короче SRE/devops.
- распределённые системы (хотя тут я тот ещё junior, но без практики чем-то большим стать и не получится).
- software development in test (я начал работу в IT с тестирования и довольно случайно стал разработчиком).
- различного рода стартапы (тут больше зависит от идеи).

Привлекает обеспечение надёжности ПО, выжимание производительности из кода и алгоритмов, оптимизации итд. Возможность делать вклад в популярные OpenSource проекты на работе, а не после неё - тоже может заманить.

## Контакты/ссылки

### Связанные с программированием

- [codewars: ![codewars rating](https://www.codewars.com/users/strizhechenko/badges/micro)](https://www.codewars.com/users/strizhechenko)
- [github](https://github.com/strizhechenko)
- [habrahabr](http://habrahabr.ru/users/weirded)
- [linkedin](https://linkedin.com/in/strizhechenko)
- [blog about Linux](http://strizhechenko.github.io)

### Прочее

- [e-mail](mailto:oleg.strizhechenko+github@gmail.com)
- [twitter](https://twitter.com/strizhechenko)

## Образование

- [Колледж связи](http://uisi.ru/) - 2008-2011, техник, программное обеспечение вычислительной техники и автоматизированных систем (красный диплом)
- [УрФУ](http://urfu.ru/) - 2012-2016, бакалавр, программная инженерия.

## Языки

- Русский (родной)
- Английский - intermediate, посещаю курсы + изучаю самостоятельно.

## Проекты в которых участовал

- 2009-2010. Начинающий системный администратор в нескольких компаниях (1 год)
- 2010-2010. Tandem University - система автоматизации ВУЗов. Q/A (тестировщик)
- 2011-2013. Ideco ASR / Ideco AS / Carbon Billing 4 - основанный на Linux софтроутер и биллинг для интернет-провайдеров размером 1000-10000 абонентов. Q/A, техническая поддержка, разработчик.
- 2012-2015. Carbon PL5 - Linux-дистрибутив для поставки приложений Carbon Soft, оформленных в виде отдельных chroot и набор утилит для управления ими. Основной разработчик, в последствии сдал проект.
- 2012-2016. Carbon Billing 5 - биллинг для интернет-провайдеров размером до 100000 абонентов. В основном помогал решать коллегам системные, специфичные для Linux и сетевые проблемы. Разработчик.
- 2012-2016. Carbon XGE Router 5 - основанный на Linux софтроутер. Занимался сетевой начинкой из файрвола, шейперов, ipset, а также максимально быстрой интеграцией с Carbon Billing 5. Основной разработчик, в последствии сдал проект.
- 2012-2016. Carbon Reductor - система фильтрации трафика для провайдеров с производительностью до 100000 абонентов на сервер. Используется более чем у 400 провайдеров в РФ. Сейчас занимаюсь только им. Ведущий разработчик, продукт менеджер.

## Навыки

Недавно я баловался с `graphviz`, возможно "[карта навыков](/images/my-skills.svg)" будет удобнее текста ниже:

### bash

Хороший язык, если код скрипта помещается на один экран.

Примеры кода:

- [Carbon Reductor Satellite](https://github.com/carbonsoft/reductor_satellite_installer) - система для проверки работы фильтрации, аналог АС Ревизор.
- [netutils-linux](https://github.com/strizhechenko/netutils-linux) - Утилиты для отладки сетевой производительности Linux.

Инструменты: vim -> atom, bash -eux, shellcheck

### python

Очень хороший язык, особенно если вся команда использует одинаковые инструменты для работы с ним. К сожалению специфика работы пока что мало даёт с ним серьёзно работать, так что в основном я его использовал в различных pet-project'ах.

Инструменты: : vim -> atom -> PyCharm CE, pylint, nosetests, pytest, ipython, cProfile.

Основные библиотеки с которыми довелось работать:

#### Веб

Flask, Flask-API, Jinja2 - на самом деле с вебом я дружу очень плохо, но иногда работать с ним приходится. Связка из этих библиотек позволяет очень быстро на коленке набросать работающее приложение/API.

Flask и Jinja2 использовал в разработке веб-интерфейса Carbon Reductor, ещё одном pet-project, показывающем удалённость нужных мне троллейбусов от часто используемых остановок.

Flask-API использовалось при написании специфической системы мониторинга и сбора телеметриии, в качестве "клея" между Python, Postgres и InfluxDB/Grafana.

#### Боты

Tweepy, Telepot, Dictator, Pymorphy2, pymarkovchain - есть у меня небольшое хобби, клепать ботов в твиттер во славу автоматической генерации забавного контента.

Tweepy лежит в основе двух врапперов для того, чтобы максимально быстро и удобно разворачивать новых ботов:

1. [twitterbot-utils](https://github.com/strizhechenko/twitterbot_utils) - набор общих сценариев использования tweepy.
2. [twitterbot-farm](https://github.com/strizhechenko/twitterbot_farm) - всё для построения связок из нескольких ботов с целью снижения числа запросов к twitter API и возможности крутить всё в одном месте, а не в heroku, где бесплатных часов довольно мало.

Pymorphy2 - в этой связке обеспечивает относительную связность речи, довольно неплохо склоняя слова. При этом места она занимает куда меньше, чем тот же NLTK.

Dictator - небольшая библиотека один раз упоминавшаяся на хабре и очень полюбившаяся мне тем, что позволяет работать с Redis как с обычным dict, что делает код в разы прозрачнее.

Telepot - за всё время пользования Lingualeo я так и не дождался появления возможности добавлять незнакомые слова списками, хотя бы по 50-200 штук. Поэтому сделал себе свой lingualeo с телеграмм-ботом, python, yandex translate API и sqlite.

#### DNS

Qdns и dnspython - делал на их основе многопоточный DNS-резолвер с довольно умным кэшем и своеобразным `gethostsbyname`, оправшивающем все доступные DNS-сервера. Требовалось для отправки заблокированных ресурсов в прокси через BGP одному из клиентов.

Помимо этого довольно много работал с DNS-серверами Unbound и Bind, сделав [готовое решение](https://github.com/carbonsoft/named_fakezone_generator) для использования их в целях фильтрации трафика.

#### API

Люблю и использую API различных сервисов и социальных сетей, таких как vk, twitter, telegram, yandex translate, uber и soundcloud для создания возможностей, которые их разработчики изначально не закладывали.

### C / C++

Linux kernel, netfilter, iptables - построил систему фильтрации трафика (анализ пакетов и MitM для HTTP и DNS) Carbon Reductor. Немного ковырял библиотеки PF_RING и NETMAP, но далеко дело не зашло. Делал нечто довольно странное - unit-тесты кода на C, в том числе и по обработке пакетов, используемого в ядерных модулях, которые работают в userspace, под Linux и OS X.

Портировал с 32 бит на 64 легаси-проект по сбору и агрегации netflow, а также добавлял в него поддержку netflow v9.

Учил Squid работать с трафиком отправленным в него с помощью DNS-спуфинга.

Инструменты: vim > atom, cmocka, gcc/clang, clang-format, clang-check, gdb, strace, gprof, make, valgrind, ftrace (и printk() :D).

Страдаю от непривычности dtrace.

### Linux

Имею большой опыт по выжиманию всех возможностей из сетевого стека linux (RPS, RSS, Coalesce/Размер буферов, RFS, выбор правильного железа для сетевых карт, особенности работы на многопроцессорных машинах).

Хорошо умею разбираться в сетевых проблемах и проблемах с производительностью серверов с помощью iproute2, ethtool, ss, procps, bind-utils, top/htop, iotop, oprofile, ftrace и т.д.

Пишу чистый и короткий shell-код (а не ворочаю 10 пайпов там, где можно обойтись одной командой), поскольку хорошо разбираюсь в coreutils, grep, awk, sed, и т.д.

Проблема: застрял на RHEL6/CentOS 6 из-за политики Carbon Soft. Вообще, хотелось бы освежить навыки и поработать с более современными системами, пощупать systemd где-то кроме домашнего localhost итд.

### Сети

Пять лет проработал более чем с 500 операторами связи из России, Беларуси и Турции в роли тестировщика, технической поддержки, разработчика и продукт менеджера. Слабо дружу с оборудованием вроде Cisco, Redback, Mikrotik, Huawei, D-Link, но имею адекватное представление о том, на что они способны, а на что - нет. Решал огромное количество проблем с анализом трафика, очень хорошо умею пользоваться tcpdump/wireshark.

### Базы данных

Никогда не вдавался в подробности вроде производительности, оптимизаций и планов запросов, ибо лез в эту степь только по необходимости. Работал с Firebird, MySQL, Postgres, Sqlite и InfluxDB.

Firebird - это основа биллинга Carbon Billing 4 и Carbon Billing 5, так что периодически приходилось написать пару запросов к ним или хранимую процедуру. Знаком с IBExpert, он хороший, хоть и неудобный.

MySQL - основа CRM vTiger, используемой в нашей компании, к которой мне пришлось делать несколько плагинов, чтобы подружить с системой мониторинга и наладить бизнес-процесс автоматического создания заявок для техподдержки.

Postgres - вдохновившись словами ведущего [@backendsecret](https://twitter.com/backendsecret) я решил таки посмотреть на возможности, которые даёт JSONB в новом postgres и мне довольно понравилось. Использовал его в качестве буфера и агрегатора для текущих данных по собираемой телеметрии перед отправкой в InfluxDB.

Sqlite - довольно неплохое решение, в котором я храню ротирующуяся статистику работы серверов с Carbon Reductor за последние 30 дней, которая используется для рисования графиков в его веб-интерфейсе. Хорошо это решение тем, что не надо беспокоиться о работе сервера БД на машинах, к которым у меня нет доступа. Единственная проблема с которой - не удалось наладить красивый процесс работы с миграциями с помощью SQLAlchemy из-за ограничений sqlite.

InfluxDB - использую её уже более двух лет для сбора и последующей визуализации самых разнообразных данных. На работе в основном это связано с бизнес метриками, такими как объём выставленных и оплаченных счетов, моя приблизительная зарплата в этом месяце, число серверов с проблемами и без, потенциальные потери, распределение обнаруженных проблем, нагрузка на техническую поддержку в виде числа открытых и незакрытых задач, результаты юнит-тестов, тестов производительности и ещё некоторая статистика. Также использую в одном из pet-project по сбору и прогнозированию данных о стоимости поездки на Uber по часто используемым мной маршрутам.

### Мониторинги, метрики

Zabbix - использую по причине того, что у него из коробки есть много готовых алертов и триггеров для Linux-серверов, а научить его писать в slack было довольно просто.

InfluxDB, Telegraf, Kapacitor, Collectd - почти TICK-стек. Сейчас в работе находится построение кастомного мониторинга за серверами крупных клиентов. Умею писать плагины для Collectd и Telegraf, чтобы собирать собственные метрики непосредственно связанные с наблюдаемым приложением. С помощью Kapacitor могу наладить правильный алертинг - о проблеме оповещаются только нужные люди и только в нужный момент времени, лишние беспокойства - зло.

### Ansible

Чудесный инструмент, которому быстро обучаются новички и который очень экономит время и снижает вероятность проблем из-за человеческого фактора. Пользуюсь ansible-lint, просмотрел курс ansible essentials от Red Hat (потому что бесплатно). До этого пытался подружиться с chef, но он близко не agentless.

### Визуализация данных

Grafana - очень удобный инструмент для исторического анализа и наблюдения за изменением трендов. Знаком с автоматизацией развёртывания с помощью ansible, вплоть до автоматического создания data-sources и dashboards.

Graphviz - полюбил строить изображения карты для описания самых разных данных и набросал для этого утилиту на основе sfdp, gvmap и neato: https://github.com/strizhechenko/gv2map. Перед этим познал нечеловечность GraphML и инструментов для работы с ним.

### Виртуализация

Активно пользуюсь. Писал себе несколько врапперов для ускорения деплоя виртуальных машин и контейнеров. В основном использовал для построения тестовых окружений, эмулирующих сеть провайдера у которого решал какую-либо проблему. Помогал клиентам добиться относительно высокой сетевой производительности, несмотря на использование виртуальной машины. Ключевые слова: OpenVZ, LXC, Libvirt, Qemu, KVM, Heroku, Digital ocean.

### Документация, блоги

Люблю выстраивать документацию, ориентированную на пользователя, очень котирую в этом плане Confluence, поскольку он позволяет выстроить документацию так, что пользователь действительно может решить свою проблему, не обращаясь в технискую поддержку. Пример: [Документация Carbon Reductor](http://docs.carbonsoft.ru/display/reductor5).

В целом люблю правильно структуризировать текст, писать статьи, вести блоги разных форматов (twitter / технические статьи), подготавливать release-notes на человеческом языке (само собой публикуются они после трёх-четырёх итераций правки маркетологами за мной и мной за маркетологами), обожаю Markdown.

### CSS

[Metro UI CSS](http://metroui.org.ua) - ничего больше не использовал (ну так, пару раз готовый код правил), вроде бы по сути тот же bootstrap. На его основе сделал [веб-интерфейс Carbon Reductor](http://demo-reductor.carbonsoft.ru).

### Javascript

Не знаю ни одного современного фреймворка и как он вообще работает тоже, в целом его не особо люблю и вообще использую NoScript. Однако вполне успешно написал себе на нём несколько скриптов для greesemonkey, чтобы было легче выбирать пиццу вместе с девушкой (она вегетарианка, а я не люблю грибы, так что все пиццы содержащие мясо и грибы на сайтах трёх ближайших пиццерий просто не отображаются).

### Вторичные навыки

go, java, php, javascript, css, letsencrypt, openssl, uwsgi, nginx, redis

### Что я хочу подучить получше

Не решить 1-2 проблемы с помощью stackoverflow, а прочитать хотя бы одну книжку по этой теме и заиметь хотя бы 100-200 часов опыта с этой технологией.

- систематизировать свои знания по computer science в области многопоточности, паралеллизма итд.
- selinux
- graphite
- systemd
- ELK Stack
- netfilter актуальной версии ядра
- continuous queries в influxdb
- docker
- openstack
- golang - написать хоть что-то, например того же твиттербота
- профилирование и оптимизация sql в postgres
- прикрутить streaming api в twitterbot-utils
- python-midi (барабаны, другие инструменты, создать виртуальный midi контроллер, подружить его с garageband, а дальше привет машинное обучение и generative music!)
- gcov
- Внутреннее устройство Kbuild и DKMS
- Правильное устройство pipeline в jenkins
- CI в Gitlab
- Использование oprofile для профилирования userspace-приложений
- Производительность nginx (чуть глубже, чем увеличения числа worker'ов и включение использования e-poll)
- Машинное обучение - закончить книжку Introducion to machine learning with Python и продолжить курсы на курсере от Andrew Ng, заброшенные на 4 неделе из-за неудобства Octave.

## Книги

### Прочитанные

- The Pragmatic Programmer
- An Introducion to programming on Go
- The Mythical Man-Month
- Cord of enouth length for shooting your leg
- C Programming language
- Linux kernel primer
- Facts and Fallacies of Software Engineering
- Dive into python
- Clean code (Bob Martin)
- Agile technologies, Extreme Programming and RUP.
- The main question of coding, refactoring and everything.
- Human factor. Successful projects and commands.
- Scrum and XP, notes from frontline
- Extreme programming
- Advanced Bash Scripting Guide
- Linux Advanced Routing and Traffic Control
- Iptables Tutorial 1.1.19
- Unix in a nutshell
- Art of the Unix programming
- Advanced Linux programming
- Network Performance Tuning (Jamie Bainbridge and Jon Maxwell)

### Читаемые

- SRE. How google runs production software.
- Introduction to machine learning with Python.

## Предпочитаемые операционные системы

- Локальная разработка: OS X / Fedora 24
- Сервера: CentOS 6 / Centos 7

## Прочая информация

- Дважды вёл в течении недели аккаунт про системное программирование [@kernelunderhood](https://twitter.com/kernelunderhood)
- Являюсь куратором аккаунта [@sorrowunderhood](https://twitter.com/sorrowunderhood), где программисты делятся худшими практиками и ноют. Дважды вёл его самостоятельно.
